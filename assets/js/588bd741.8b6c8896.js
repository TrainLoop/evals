"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[324],{3014:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"getting-started/quick-start","title":"Quick Start Guide","description":"Get up and running with TrainLoop Evals in under 5 minutes. This guide walks you through setting up your first evaluation project, collecting LLM data, and running your first evaluations.","source":"@site/docs/getting-started/quick-start.md","sourceDirName":"getting-started","slug":"/getting-started/quick-start","permalink":"/evals/getting-started/quick-start","draft":false,"unlisted":false,"editUrl":"https://github.com/TrainLoop/evals/tree/main/docs/docs/getting-started/quick-start.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Installation","permalink":"/evals/getting-started/installation"},"next":{"title":"Introduction to TrainLoop Evals","permalink":"/evals/intro"}}');var r=t(4848),s=t(8453);const a={sidebar_position:2},o="Quick Start Guide",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Step 1: Create Your Workspace",id:"step-1-create-your-workspace",level:2},{value:"Step 2: Set Up Data Collection",id:"step-2-set-up-data-collection",level:2},{value:"Step 3: Instrument Your Application",id:"step-3-instrument-your-application",level:2},{value:"Python Application",id:"python-application",level:3},{value:"TypeScript/JavaScript Application",id:"typescriptjavascript-application",level:3},{value:"Go Application",id:"go-application",level:3},{value:"Step 4: Write Your First Metric",id:"step-4-write-your-first-metric",level:2},{value:"Step 5: Create Your First Test Suite",id:"step-5-create-your-first-test-suite",level:2},{value:"Step 6: Run Your First Evaluation",id:"step-6-run-your-first-evaluation",level:2},{value:"Step 7: Visualize Results",id:"step-7-visualize-results",level:2},{value:"Step 8: Iterate and Improve",id:"step-8-iterate-and-improve",level:2},{value:"Next Steps",id:"next-steps",level:2},{value:"\ud83d\udd27 Advanced Configuration",id:"-advanced-configuration",level:3},{value:"\ud83d\udcca Benchmarking",id:"-benchmarking",level:3},{value:"\ud83c\udfaf Advanced Metrics",id:"-advanced-metrics",level:3},{value:"\ud83d\udd0d Registry System",id:"-registry-system",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"No data collected",id:"no-data-collected",level:4},{value:"Evaluation fails",id:"evaluation-fails",level:4},{value:"Studio UI doesn&#39;t show data",id:"studio-ui-doesnt-show-data",level:4},{value:"Getting Help",id:"getting-help",level:3},{value:"Congratulations! \ud83c\udf89",id:"congratulations-",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"quick-start-guide",children:"Quick Start Guide"})}),"\n",(0,r.jsx)(n.p,{children:"Get up and running with TrainLoop Evals in under 5 minutes. This guide walks you through setting up your first evaluation project, collecting LLM data, and running your first evaluations."}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"In this quick start, you'll:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Create a workspace"})," - Set up the TrainLoop directory structure"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Instrument your app"})," - Add data collection to your LLM calls"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Write your first metric"})," - Create a simple evaluation function"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Run evaluations"})," - Execute your first evaluation suite"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Visualize results"})," - View results in the Studio UI"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-1-create-your-workspace",children:"Step 1: Create Your Workspace"}),"\n",(0,r.jsx)(n.p,{children:"First, create a new directory for your project and initialize TrainLoop:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir my-llm-project\ncd my-llm-project\ntrainloop init\n"})}),"\n",(0,r.jsx)(n.p,{children:"This creates the following structure:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"my-llm-project/\n\u251c\u2500\u2500 trainloop/\n\u2502   \u251c\u2500\u2500 data/                 # Data storage (auto-created)\n\u2502   \u251c\u2500\u2500 eval/                 # Your evaluation code\n\u2502   \u2502   \u251c\u2500\u2500 metrics/          # Custom metrics\n\u2502   \u2502   \u2514\u2500\u2500 suites/           # Test suites\n\u2502   \u2514\u2500\u2500 trainloop.config.yaml # Configuration\n\u2514\u2500\u2500 .gitignore               # Pre-configured for TrainLoop\n"})}),"\n",(0,r.jsx)(n.h2,{id:"step-2-set-up-data-collection",children:"Step 2: Set Up Data Collection"}),"\n",(0,r.jsx)(n.p,{children:"Configure where your LLM interaction data will be stored:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Set the data folder environment variable\nexport TRAINLOOP_DATA_FOLDER="$(pwd)/trainloop/data"\n\n# Or add it to your shell profile for persistence\necho \'export TRAINLOOP_DATA_FOLDER="$(pwd)/trainloop/data"\' >> ~/.bashrc\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-3-instrument-your-application",children:"Step 3: Instrument Your Application"}),"\n",(0,r.jsx)(n.p,{children:"Choose your application's language and follow the appropriate instructions:"}),"\n",(0,r.jsx)(n.h3,{id:"python-application",children:"Python Application"}),"\n",(0,r.jsx)(n.p,{children:"Create a simple Python script that makes LLM calls:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# app.py\nimport openai\nfrom trainloop_llm_logging import collect, trainloop_tag\n\n# Initialize TrainLoop collection\ncollect("trainloop/trainloop.config.yaml")\n\n# Set up OpenAI client\nclient = openai.OpenAI(api_key="your-api-key")\n\ndef generate_greeting(name):\n    """Generate a personalized greeting"""\n    response = client.chat.completions.create(\n        model="gpt-4o-mini",\n        messages=[\n            {"role": "system", "content": "You are a friendly assistant."},\n            {"role": "user", "content": f"Generate a warm greeting for {name}"}\n        ],\n        extra_headers=trainloop_tag("greeting-generation")  # Tag for evaluation\n    )\n    return response.choices[0].message.content\n\n# Test the function\nif __name__ == "__main__":\n    greeting = generate_greeting("Alice")\n    print(f"Generated greeting: {greeting}")\n'})}),"\n",(0,r.jsx)(n.p,{children:"Run your application:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"python app.py\n"})}),"\n",(0,r.jsx)(n.h3,{id:"typescriptjavascript-application",children:"TypeScript/JavaScript Application"}),"\n",(0,r.jsx)(n.p,{children:"Create a Node.js application:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-javascript",children:'// app.js\nconst { OpenAI } = require(\'openai\');\nconst { trainloopTag } = require(\'trainloop-llm-logging\');\n\n// Set up OpenAI client\nconst client = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n});\n\nasync function generateGreeting(name) {\n  const response = await client.chat.completions.create({\n    model: "gpt-4o-mini",\n    messages: [\n      { role: "system", content: "You are a friendly assistant." },\n      { role: "user", content: `Generate a warm greeting for ${name}` }\n    ]\n  }, {\n    headers: { ...trainloopTag("greeting-generation") }  // Tag for evaluation\n  });\n  \n  return response.choices[0].message.content;\n}\n\n// Test the function\ngenerateGreeting("Alice").then(greeting => {\n  console.log(`Generated greeting: ${greeting}`);\n});\n'})}),"\n",(0,r.jsx)(n.p,{children:"Run your application with TrainLoop instrumentation:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'TRAINLOOP_DATA_FOLDER=./trainloop/data NODE_OPTIONS="--require=trainloop-llm-logging" node app.js\n'})}),"\n",(0,r.jsx)(n.h3,{id:"go-application",children:"Go Application"}),"\n",(0,r.jsx)(n.p,{children:"Create a Go application:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-go",children:'// main.go\npackage main\n\nimport (\n    "context"\n    "fmt"\n    "log"\n    "os"\n    \n    "github.com/sashabaranov/go-openai"\n    trainloop "github.com/TrainLoop/trainloop-llm-logging/go/trainloop-llm-logging"\n)\n\nfunc main() {\n    // Initialize TrainLoop\n    trainloop.Init()\n    \n    // Set up OpenAI client\n    client := openai.NewClient(os.Getenv("OPENAI_API_KEY"))\n    \n    // Generate greeting\n    greeting := generateGreeting(client, "Alice")\n    fmt.Printf("Generated greeting: %s\\n", greeting)\n}\n\nfunc generateGreeting(client *openai.Client, name string) string {\n    resp, err := client.CreateChatCompletion(\n        context.Background(),\n        openai.ChatCompletionRequest{\n            Model: openai.GPT4OMini,\n            Messages: []openai.ChatCompletionMessage{\n                {Role: openai.ChatMessageRoleSystem, Content: "You are a friendly assistant."},\n                {Role: openai.ChatMessageRoleUser, Content: fmt.Sprintf("Generate a warm greeting for %s", name)},\n            },\n        },\n    )\n    \n    if err != nil {\n        log.Fatal(err)\n    }\n    \n    return resp.Choices[0].Message.Content\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-4-write-your-first-metric",children:"Step 4: Write Your First Metric"}),"\n",(0,r.jsx)(n.p,{children:"Create a simple metric to evaluate greeting quality:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# trainloop/eval/metrics/greeting_quality.py\nfrom trainloop_cli.eval_core.types import Sample\n\ndef has_greeting_word(sample: Sample) -> int:\n    """Check if the response contains common greeting words"""\n    response_text = sample.output.get("content", "").lower()\n    greeting_words = ["hello", "hi", "greetings", "welcome", "good morning", "good afternoon", "good evening"]\n    \n    for word in greeting_words:\n        if word in response_text:\n            return 1  # Pass\n    return 0  # Fail\n\ndef is_personalized(sample: Sample) -> int:\n    """Check if the response appears to be personalized"""\n    response_text = sample.output.get("content", "").lower()\n    \n    # Get the user\'s input to find the name\n    user_message = ""\n    for msg in sample.input.get("messages", []):\n        if msg.get("role") == "user":\n            user_message = msg.get("content", "").lower()\n            break\n    \n    # Simple check: if user message contains a name and response contains it\n    if "alice" in user_message and "alice" in response_text:\n        return 1  # Pass\n    return 0  # Fail\n\ndef is_friendly_tone(sample: Sample) -> int:\n    """Check if the response has a friendly tone using LLM Judge"""\n    from trainloop_cli.eval_core.judge import assert_true\n    \n    response_text = sample.output.get("content", "")\n    \n    positive_claim = f"The response \'{response_text}\' has a warm and friendly tone."\n    negative_claim = f"The response \'{response_text}\' is cold or unfriendly."\n    \n    return assert_true(positive_claim, negative_claim)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-5-create-your-first-test-suite",children:"Step 5: Create Your First Test Suite"}),"\n",(0,r.jsx)(n.p,{children:"Create a test suite that uses your metrics:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# trainloop/eval/suites/greeting_evaluation.py\nfrom trainloop_cli.eval_core.helpers import tag\nfrom ..metrics.greeting_quality import has_greeting_word, is_personalized, is_friendly_tone\n\n# Test all greeting generation calls\nresults = tag("greeting-generation").check(\n    has_greeting_word,\n    is_personalized,\n    is_friendly_tone\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"step-6-run-your-first-evaluation",children:"Step 6: Run Your First Evaluation"}),"\n",(0,r.jsx)(n.p,{children:"Execute your evaluation suite:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Run all evaluation suites\ntrainloop eval\n\n# Or run a specific suite\ntrainloop eval --suite greeting_evaluation\n"})}),"\n",(0,r.jsx)(n.p,{children:"You should see output like:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\ud83d\udd0d Discovering evaluation suites...\n\u2705 Found 1 suite: greeting_evaluation\n\n\ud83d\udcca Running evaluations...\n\u2705 greeting_evaluation: 3/3 metrics passed\n\n\ud83d\udcc8 Results saved to trainloop/data/results/\n"})}),"\n",(0,r.jsx)(n.h2,{id:"step-7-visualize-results",children:"Step 7: Visualize Results"}),"\n",(0,r.jsx)(n.p,{children:"Launch the Studio UI to explore your results:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"trainloop studio\n"})}),"\n",(0,r.jsxs)(n.p,{children:["This opens your browser to ",(0,r.jsx)(n.code,{children:"http://localhost:3000"})," where you can:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"\ud83d\udcca View evaluation results in interactive charts"}),"\n",(0,r.jsx)(n.li,{children:"\ud83d\udccb Browse individual LLM calls and their evaluations"}),"\n",(0,r.jsx)(n.li,{children:"\ud83d\udcc8 Track metrics over time"}),"\n",(0,r.jsx)(n.li,{children:"\ud83d\udd0d Filter and search through your data"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"step-8-iterate-and-improve",children:"Step 8: Iterate and Improve"}),"\n",(0,r.jsx)(n.p,{children:"Based on your evaluation results, you can:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Refine your prompts"})," - Improve system messages for better results"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Add more metrics"})," - Create additional evaluation criteria"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Test different models"})," - Compare performance across LLM providers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Automate evaluations"})," - Run evaluations in CI/CD pipelines"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsx)(n.p,{children:"Now that you have a working TrainLoop Evals setup, explore these advanced features:"}),"\n",(0,r.jsx)(n.h3,{id:"-advanced-configuration",children:"\ud83d\udd27 Advanced Configuration"}),"\n",(0,r.jsxs)(n.p,{children:["Configure TrainLoop behavior in ",(0,r.jsx)(n.code,{children:"trainloop.config.yaml"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'trainloop:\n  data_folder: "./data"\n  log_level: "info"\n  \n  # LLM Judge configuration\n  judge:\n    models:\n      - openai/gpt-4o\n      - anthropic/claude-3-sonnet-20240229\n    calls_per_model_per_claim: 3\n    temperature: 0.7\n    \n  # Benchmarking configuration\n  benchmark:\n    providers:\n      - openai/gpt-4o\n      - openai/gpt-4o-mini\n      - anthropic/claude-3-5-sonnet-20241022\n    temperature: 0.7\n    max_tokens: 1000\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-benchmarking",children:"\ud83d\udcca Benchmarking"}),"\n",(0,r.jsx)(n.p,{children:"Compare multiple LLM providers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Add API keys to .env file\ncp trainloop/.env.example trainloop/.env\n# Edit trainloop/.env with your API keys\n\n# Run benchmarks\ntrainloop benchmark\n"})}),"\n",(0,r.jsx)(n.h3,{id:"-advanced-metrics",children:"\ud83c\udfaf Advanced Metrics"}),"\n",(0,r.jsx)(n.p,{children:"Create more sophisticated evaluation metrics:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# trainloop/eval/metrics/advanced_metrics.py\nfrom trainloop_cli.eval_core.types import Sample\nfrom trainloop_cli.eval_core.judge import assert_true\nimport json\n\ndef response_length_appropriate(sample: Sample) -> int:\n    """Check if response length is appropriate for the task"""\n    response_text = sample.output.get("content", "")\n    word_count = len(response_text.split())\n    \n    # Greeting should be between 5-50 words\n    return 1 if 5 <= word_count <= 50 else 0\n\ndef follows_instructions(sample: Sample) -> int:\n    """Check if the response follows the given instructions"""\n    response_text = sample.output.get("content", "")\n    \n    # Use LLM Judge for complex evaluation\n    instruction_claim = f"The response \'{response_text}\' follows the instruction to generate a warm greeting."\n    violation_claim = f"The response \'{response_text}\' does not follow the instruction to generate a warm greeting."\n    \n    return assert_true(instruction_claim, violation_claim)\n'})}),"\n",(0,r.jsx)(n.h3,{id:"-registry-system",children:"\ud83d\udd0d Registry System"}),"\n",(0,r.jsx)(n.p,{children:"Add pre-built metrics and suites:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# List available components\ntrainloop add --list\n\n# Add a metric from the registry\ntrainloop add metric always_pass\n\n# Add a suite from the registry\ntrainloop add suite sample\n"})}),"\n",(0,r.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,r.jsx)(n.h4,{id:"no-data-collected",children:"No data collected"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Ensure ",(0,r.jsx)(n.code,{children:"TRAINLOOP_DATA_FOLDER"})," is set correctly"]}),"\n",(0,r.jsx)(n.li,{children:"Check that your LLM calls are being made"}),"\n",(0,r.jsx)(n.li,{children:"Verify the SDK is properly initialized"}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"evaluation-fails",children:"Evaluation fails"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Check that your metric functions return integers (0 or 1)"}),"\n",(0,r.jsxs)(n.li,{children:["Ensure the ",(0,r.jsx)(n.code,{children:"results"})," variable is defined in your suite files"]}),"\n",(0,r.jsx)(n.li,{children:"Verify your tag names match between data collection and evaluation"}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"studio-ui-doesnt-show-data",children:"Studio UI doesn't show data"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Confirm evaluations have been run (",(0,r.jsx)(n.code,{children:"trainloop eval"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:["Check that result files exist in ",(0,r.jsx)(n.code,{children:"trainloop/data/results/"})]}),"\n",(0,r.jsx)(n.li,{children:"Try refreshing the browser or restarting the Studio"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"getting-help",children:"Getting Help"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Documentation"}),": Browse the ",(0,r.jsx)(n.a,{href:"../guides/",children:"guides"})," and ",(0,r.jsx)(n.a,{href:"../reference/",children:"reference"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GitHub Issues"}),": ",(0,r.jsx)(n.a,{href:"https://github.com/TrainLoop/trainloop-evals/issues",children:"Report bugs or ask questions"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Examples"}),": Check the ",(0,r.jsx)(n.a,{href:"https://github.com/TrainLoop/chat-ui-demo",children:"demo repository"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"congratulations-",children:"Congratulations! \ud83c\udf89"}),"\n",(0,r.jsx)(n.p,{children:"You've successfully set up TrainLoop Evals and created your first evaluation workflow. You're now ready to build robust, data-driven evaluations for your LLM applications."}),"\n",(0,r.jsxs)(n.p,{children:["Continue with the ",(0,r.jsx)(n.a,{href:"../guides/",children:"guides"})," to learn about advanced features, or explore the ",(0,r.jsx)(n.a,{href:"../reference/",children:"reference documentation"})," for detailed API information."]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>o});var i=t(6540);const r={},s=i.createContext(r);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);