"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1373],{8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>o});var s=t(6540);const i={},r=s.createContext(i);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:n},e.children)}},9453:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"development/sdk-testing","title":"SDK Testing Guide","description":"This document describes how to run tests for both Python and TypeScript SDKs in the TrainLoop Evals ecosystem.","source":"@site/docs/development/sdk-testing.md","sourceDirName":"development","slug":"/development/sdk-testing","permalink":"/development/sdk-testing","draft":false,"unlisted":false,"editUrl":"https://github.com/trainloop/evals/tree/main/docs/docs/development/sdk-testing.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Development Guide","permalink":"/development/"},"next":{"title":"Release Process","permalink":"/development/release-process"}}');var i=t(4848),r=t(8453);const l={sidebar_position:4},o="SDK Testing Guide",c={},d=[{value:"Overview",id:"overview",level:2},{value:"Python SDK Testing",id:"python-sdk-testing",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Running Tests",id:"running-tests",level:3},{value:"Test Structure",id:"test-structure",level:3},{value:"Test Markers",id:"test-markers",level:3},{value:"TypeScript SDK Testing",id:"typescript-sdk-testing",level:2},{value:"Prerequisites",id:"prerequisites-1",level:3},{value:"Running Tests",id:"running-tests-1",level:3},{value:"Test Structure",id:"test-structure-1",level:3},{value:"Test Architecture",id:"test-architecture",level:2},{value:"Clean Code Separation",id:"clean-code-separation",level:3},{value:"TypeScript Test Setup",id:"typescript-test-setup",level:3},{value:"Python Test Setup",id:"python-test-setup",level:3},{value:"Common Test Scenarios",id:"common-test-scenarios",level:2},{value:"Configuration Tests",id:"configuration-tests",level:3},{value:"HTTP Instrumentation Tests",id:"http-instrumentation-tests",level:3},{value:"Storage Tests",id:"storage-tests",level:3},{value:"Parser Tests",id:"parser-tests",level:3},{value:"Exporter Tests",id:"exporter-tests",level:3},{value:"Writing New Tests",id:"writing-new-tests",level:2},{value:"Python Example",id:"python-example",level:3},{value:"TypeScript Example",id:"typescript-example",level:3},{value:"Continuous Integration",id:"continuous-integration",level:2},{value:"Debugging Tests",id:"debugging-tests",level:2},{value:"Python",id:"python",level:3},{value:"TypeScript",id:"typescript",level:3},{value:"Coverage Goals",id:"coverage-goals",level:2},{value:"Integration with CLI Testing",id:"integration-with-cli-testing",level:2},{value:"Performance Testing",id:"performance-testing",level:2},{value:"Python SDK Performance",id:"python-sdk-performance",level:3},{value:"TypeScript SDK Performance",id:"typescript-sdk-performance",level:3},{value:"Mock LLM Providers",id:"mock-llm-providers",level:2},{value:"Python",id:"python-1",level:3},{value:"TypeScript",id:"typescript-1",level:3},{value:"Best Practices",id:"best-practices",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"sdk-testing-guide",children:"SDK Testing Guide"})}),"\n",(0,i.jsx)(n.p,{children:"This document describes how to run tests for both Python and TypeScript SDKs in the TrainLoop Evals ecosystem."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Both SDKs have comprehensive test suites covering:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Unit tests"}),": Test individual components in isolation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Integration tests"}),": Test components working together"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Edge case tests"}),": Test boundary conditions and error scenarios"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"python-sdk-testing",children:"Python SDK Testing"}),"\n",(0,i.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd sdk/python\npoetry install\n"})}),"\n",(0,i.jsx)(n.h3,{id:"running-tests",children:"Running Tests"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run all tests\npoetry run pytest\n\n# Run with coverage\npoetry run pytest --cov\n\n# Run specific test categories\npoetry run pytest -m unit              # Unit tests only\npoetry run pytest -m integration       # Integration tests only\npoetry run pytest -m edge_case         # Edge case tests only\n\n# Run tests in parallel\npoetry run pytest -n auto\n\n# Run specific test file\npoetry run pytest tests/unit/test_config.py\n\n# Run with verbose output\npoetry run pytest -v\n\n# Generate HTML coverage report\npoetry run pytest --cov --cov-report=html\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-structure",children:"Test Structure"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"sdk/python/tests/\n\u251c\u2500\u2500 conftest.py          # Shared fixtures and configuration\n\u251c\u2500\u2500 unit/                # Unit tests\n\u2502   \u251c\u2500\u2500 test_config.py\n\u2502   \u251c\u2500\u2500 test_exporter.py\n\u2502   \u251c\u2500\u2500 test_store.py\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 integration/         # Integration tests\n\u2502   \u251c\u2500\u2500 test_collection.py\n\u2502   \u251c\u2500\u2500 test_instrumentation.py\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 edge_cases/          # Edge case tests\n    \u251c\u2500\u2500 test_config_edge_cases.py\n    \u251c\u2500\u2500 test_network_edge_cases.py\n    \u2514\u2500\u2500 ...\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-markers",children:"Test Markers"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.unit"}),": Unit tests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.integration"}),": Integration tests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.slow"}),": Slow tests (>1s)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.edge_case"}),": Edge case tests"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.requires_network"}),": Tests requiring network access"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"@pytest.mark.requires_fs"}),": Tests requiring filesystem access"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"typescript-sdk-testing",children:"TypeScript SDK Testing"}),"\n",(0,i.jsx)(n.h3,{id:"prerequisites-1",children:"Prerequisites"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd sdk/typescript\nnpm install\n"})}),"\n",(0,i.jsx)(n.h3,{id:"running-tests-1",children:"Running Tests"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run all tests\nnpm test\n\n# Run with coverage\nnpm run test:coverage\n\n# Run specific test categories\nnpm run test:unit              # Unit tests only\nnpm run test:integration       # Integration tests only\nnpm run test:edge             # Edge case tests only\n\n# Run in watch mode\nnpm run test:watch\n\n# Run specific test file\nnpm test -- config.test.ts\n\n# Generate coverage report\nnpm run test:coverage\n"})}),"\n",(0,i.jsx)(n.h3,{id:"test-structure-1",children:"Test Structure"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"sdk/typescript/tests/\n\u251c\u2500\u2500 setup.ts             # Jest setup and configuration\n\u251c\u2500\u2500 test-utils.ts        # Shared test utilities\n\u251c\u2500\u2500 unit/                # Unit tests\n\u2502   \u251c\u2500\u2500 config.test.ts\n\u2502   \u251c\u2500\u2500 exporter.test.ts\n\u2502   \u251c\u2500\u2500 store.test.ts\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 integration/         # Integration tests\n\u2502   \u251c\u2500\u2500 collection.test.ts\n\u2502   \u251c\u2500\u2500 instrumentation.test.ts\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 edge-cases/          # Edge case tests\n\u2502   \u251c\u2500\u2500 config-edge.test.ts\n\u2502   \u251c\u2500\u2500 network-edge.test.ts\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 fixtures/            # Test data and fixtures\n"})}),"\n",(0,i.jsx)(n.h2,{id:"test-architecture",children:"Test Architecture"}),"\n",(0,i.jsx)(n.h3,{id:"clean-code-separation",children:"Clean Code Separation"}),"\n",(0,i.jsx)(n.p,{children:"The SDKs maintain clean separation between production and test code:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"No test logic in production code"}),": The main SDK files (e.g., ",(0,i.jsx)(n.code,{children:"index.ts"}),") contain only production code"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test isolation via mocking"}),": Tests mock the FileExporter to prevent background timers and file I/O"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Graceful shutdown"}),": The ",(0,i.jsx)(n.code,{children:"shutdown()"})," function is useful for both production (graceful shutdown) and tests (cleanup)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"typescript-test-setup",children:"TypeScript Test Setup"}),"\n",(0,i.jsxs)(n.p,{children:["The TypeScript test setup (",(0,i.jsx)(n.code,{children:"tests/setup.ts"}),") handles:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Setting test environment variables"}),"\n",(0,i.jsx)(n.li,{children:"Mocking the FileExporter to prevent background operations"}),"\n",(0,i.jsx)(n.li,{children:"Suppressing console output during tests"}),"\n",(0,i.jsx)(n.li,{children:"Cleaning up after all tests complete"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"python-test-setup",children:"Python Test Setup"}),"\n",(0,i.jsxs)(n.p,{children:["The Python test setup (",(0,i.jsx)(n.code,{children:"tests/conftest.py"}),") provides:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Fixtures for temporary directories and files"}),"\n",(0,i.jsx)(n.li,{children:"Environment variable management"}),"\n",(0,i.jsx)(n.li,{children:"Mock objects for testing without side effects"}),"\n",(0,i.jsx)(n.li,{children:"Sample request/response data for different LLM providers"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"common-test-scenarios",children:"Common Test Scenarios"}),"\n",(0,i.jsx)(n.h3,{id:"configuration-tests",children:"Configuration Tests"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Missing environment variables"}),"\n",(0,i.jsx)(n.li,{children:"Invalid YAML syntax"}),"\n",(0,i.jsx)(n.li,{children:"Missing config files"}),"\n",(0,i.jsx)(n.li,{children:"Path resolution (absolute/relative)"}),"\n",(0,i.jsx)(n.li,{children:"Environment variable precedence"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"http-instrumentation-tests",children:"HTTP Instrumentation Tests"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Different HTTP libraries (requests, httpx, urllib)"}),"\n",(0,i.jsx)(n.li,{children:"Network failures"}),"\n",(0,i.jsx)(n.li,{children:"Timeouts"}),"\n",(0,i.jsx)(n.li,{children:"Invalid responses"}),"\n",(0,i.jsx)(n.li,{children:"Large payloads"}),"\n",(0,i.jsx)(n.li,{children:"Concurrent requests"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"storage-tests",children:"Storage Tests"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"File system permissions"}),"\n",(0,i.jsx)(n.li,{children:"Disk full scenarios"}),"\n",(0,i.jsx)(n.li,{children:"Concurrent writes"}),"\n",(0,i.jsx)(n.li,{children:"Registry corruption"}),"\n",(0,i.jsx)(n.li,{children:"Invalid data formats"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"parser-tests",children:"Parser Tests"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"OpenAI format parsing"}),"\n",(0,i.jsx)(n.li,{children:"Anthropic format parsing"}),"\n",(0,i.jsx)(n.li,{children:"Malformed JSON"}),"\n",(0,i.jsx)(n.li,{children:"Missing fields"}),"\n",(0,i.jsx)(n.li,{children:"Streaming responses"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"exporter-tests",children:"Exporter Tests"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Buffer management"}),"\n",(0,i.jsx)(n.li,{children:"Timer cleanup"}),"\n",(0,i.jsx)(n.li,{children:"Export failures"}),"\n",(0,i.jsx)(n.li,{children:"Shutdown handling"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"writing-new-tests",children:"Writing New Tests"}),"\n",(0,i.jsx)(n.h3,{id:"python-example",children:"Python Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import pytest\nfrom trainloop_llm_logging import collect\n\n@pytest.mark.unit\ndef test_my_feature(temp_data_dir, mock_env_vars):\n    """Test description."""\n    # Arrange\n    os.environ["TRAINLOOP_DATA_FOLDER"] = temp_data_dir\n    \n    # Act\n    result = my_function()\n    \n    # Assert\n    assert result == expected_value\n'})}),"\n",(0,i.jsx)(n.h3,{id:"typescript-example",children:"TypeScript Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { myFunction } from '../../src/myModule';\nimport { createTempDir, cleanupTempDir } from '../test-utils';\n\ndescribe('My Feature', () => {\n  let tempDir: string;\n\n  beforeEach(() => {\n    tempDir = createTempDir();\n  });\n\n  afterEach(() => {\n    cleanupTempDir(tempDir);\n  });\n\n  it('should do something', () => {\n    // Arrange\n    process.env.TRAINLOOP_DATA_FOLDER = tempDir;\n    \n    // Act\n    const result = myFunction();\n    \n    // Assert\n    expect(result).toBe(expectedValue);\n  });\n});\n"})}),"\n",(0,i.jsx)(n.h2,{id:"continuous-integration",children:"Continuous Integration"}),"\n",(0,i.jsx)(n.p,{children:"Both test suites are designed to run in CI environments:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Tests run in isolated environments"}),"\n",(0,i.jsx)(n.li,{children:"No external dependencies required"}),"\n",(0,i.jsx)(n.li,{children:"Temporary files are cleaned up"}),"\n",(0,i.jsx)(n.li,{children:"Console output is suppressed"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"debugging-tests",children:"Debugging Tests"}),"\n",(0,i.jsx)(n.h3,{id:"python",children:"Python"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Run with debugging output\npoetry run pytest -s\n\n# Run with breakpoint\npoetry run pytest --pdb\n\n# Run specific test with verbose output\npoetry run pytest -v -k "test_name"\n'})}),"\n",(0,i.jsx)(n.h3,{id:"typescript",children:"TypeScript"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Run with debugging\nnode --inspect-brk ./node_modules/.bin/jest --runInBand\n\n# Run specific test\nnpm test -- --testNamePattern="test name"\n\n# Show console output\nnpm test -- --verbose\n'})}),"\n",(0,i.jsx)(n.h2,{id:"coverage-goals",children:"Coverage Goals"}),"\n",(0,i.jsx)(n.p,{children:"Both SDKs aim for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"80%+ line coverage"}),"\n",(0,i.jsx)(n.li,{children:"80%+ branch coverage"}),"\n",(0,i.jsx)(n.li,{children:"80%+ function coverage"}),"\n",(0,i.jsx)(n.li,{children:"Critical paths at 100% coverage"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"View coverage reports:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Python: ",(0,i.jsx)(n.code,{children:"open htmlcov/index.html"})]}),"\n",(0,i.jsxs)(n.li,{children:["TypeScript: ",(0,i.jsx)(n.code,{children:"open coverage/lcov-report/index.html"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"integration-with-cli-testing",children:"Integration with CLI Testing"}),"\n",(0,i.jsx)(n.p,{children:"SDK tests integrate with the broader CLI testing framework:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run all tests including CLI integration\npytest\n\n# Run SDK-specific integration tests\npytest -m sdk\n\n# Run full integration test suite\npytest -m integration\n"})}),"\n",(0,i.jsx)(n.h2,{id:"performance-testing",children:"Performance Testing"}),"\n",(0,i.jsx)(n.h3,{id:"python-sdk-performance",children:"Python SDK Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run performance benchmarks\npoetry run pytest tests/performance/ -v\n\n# Profile memory usage\npoetry run pytest --profile tests/unit/test_exporter.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"typescript-sdk-performance",children:"TypeScript SDK Performance"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Run performance tests\nnpm run test:performance\n\n# Profile memory and CPU usage\nnpm run test:profile\n"})}),"\n",(0,i.jsx)(n.h2,{id:"mock-llm-providers",children:"Mock LLM Providers"}),"\n",(0,i.jsx)(n.p,{children:"For testing without hitting real APIs:"}),"\n",(0,i.jsx)(n.h3,{id:"python-1",children:"Python"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from tests.helpers.mock_llm import MockOpenAI, MockAnthropic\n\n@pytest.fixture\ndef mock_openai():\n    return MockOpenAI(responses=["Test response"])\n'})}),"\n",(0,i.jsx)(n.h3,{id:"typescript-1",children:"TypeScript"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-typescript",children:"import { mockLLMProvider } from '../test-utils';\n\ndescribe('LLM Integration', () => {\n  beforeEach(() => {\n    mockLLMProvider('openai', { response: 'Test response' });\n  });\n});\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Isolate tests"}),": Each test should be independent"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use meaningful names"}),": Test names should describe what is being tested"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test edge cases"}),": Include boundary conditions and error scenarios"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mock external dependencies"}),": Don't rely on external services"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Keep tests fast"}),": Unit tests should run in milliseconds"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Clean up resources"}),": Ensure temporary files and connections are closed"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use fixtures"}),": Share common setup code via fixtures"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test error paths"}),": Verify error handling works correctly"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}}}]);