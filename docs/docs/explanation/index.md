---
sidebar_position: 1
---

# Understanding TrainLoop Evals

This section provides in-depth explanations of TrainLoop Evals concepts, architecture, and design decisions. These guides help you understand the "why" behind TrainLoop Evals.

## Core Concepts

### Architecture Overview
Learn about the overall system architecture and how components work together.

### Data Model
Understand how TrainLoop Evals stores and processes evaluation data.

### Evaluation Engine
Deep dive into how metrics and suites are executed and results are generated.

### LLM Judge System
Explore the built-in AI-powered evaluation system for subjective metrics.

## Design Principles

### Simplicity First
How TrainLoop Evals prioritizes developer experience and ease of use.

### Vendor Independence
Why and how TrainLoop Evals avoids vendor lock-in.

### Type Safety
The benefits of type-safe evaluation code and how it's implemented.

### Composability
How the modular design enables reusable evaluation components.

## Technical Deep Dives

### SDK Architecture
How the multi-language SDKs work under the hood.

### Data Collection Pipeline
The journey from LLM call to stored event data.

### Evaluation Execution
How evaluations are discovered, executed, and results are stored.

### Studio UI Architecture
The technology stack and data flow in the visualization interface.

## Coming Soon

We're working on comprehensive explanations for each of these topics. Check back soon for detailed guides that help you understand the inner workings of TrainLoop Evals.

## Questions?

If you have specific questions about how TrainLoop Evals works, please:

- Check the [Guides](../guides/) for practical how-to information
- Review the [Reference](../reference/) for API details
- [Open an issue](https://github.com/TrainLoop/trainloop-evals/issues) for technical questions